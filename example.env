# Output directory where the models and logs go
# Should not be the same with working directory
# Since that would slow down the IDE.
OUTPUT_DIR=/opt/tuesearch

##################################
# Database variables
##################################
# Experiment with different strategies
# Store each priority queue's strategy in a different database
MYSQL_DATABASE=get_highest_priority_jobs
MYSQL_USER=tuesearch
MYSQL_PASSWORD=tuesearch
MYSQL_ROOT_PASSWORD=root
MYSQL_PORT=3306
MYSQL_HOST=mysql

##################################
# Variables to configure the
# communication process
# between worker and master
##################################
# Where to retrieve jobs
CRAWLER_MANAGER_PORT=6000

# Where to retrieve jobs
CRAWLER_MANAGER_HOST=http://manager:${CRAWLER_MANAGER_PORT}

# Password
CRAWLER_MANAGER_PASSWORD=pw

# How many jobs to request from the manager at once.
# At most.
CRAWLER_MANAGER_MAX_JOB_REQUESTS=8

# Number of jobs to be crawled in a single batch.
# The higher the number,
# the less frequent the manager will ask for new jobs.
CRAWL_WORKER_BATCH_SIZE=4

# Timeout (in seconds) when communicate with crawler manager.
CRAWLER_WORKER_TIMEOUT=30

##################################
# Queue initialization variables
##################################

# List of manually added seed URLs for the crawling queue.
QUEUE_MANUAL_SEEDS='["https://www.krone-tuebingen.de/en/a-holiday-in-tuebingen/tuebingen-the-surrounding-area/","https://bestplacesnthings.com/places-to-visit-tubingen-baden-wurttemberg-germany/","https://thespicyjourney.com/magical-things-to-do-in-tubingen-in-one-day-tuebingen-germany-travel-guide/","https://velvetescape.com/things-to-do-in-tubingen/","https://justinpluslauren.com/things-to-do-in-tubingen-germany/","https://www.yelp.com/search?cflt=food&find_loc=T%C3%BCbingen%2C+Baden-W%C3%BCrttemberg","https://www.outdooractive.com/en/places-to-eat-drink/tuebingen/eat-drink-in-tuebingen/21873363/","https://wanderlog.com/list/geoCategory/199488/where-to-eat-best-restaurants-in-tubingen","https://www.tripadvisor.com/Attractions-g198539-Activities-Tubingen_Baden_Wurttemberg.html","https://www.kloster-bebenhausen.de/en/","https://www.tuebingen.de/en/","https://en.wikipedia.org/wiki/T%C3%BCbingen","https://uni-tuebingen.de/en/university/news-and-publications/press-releases/","https://uni-tuebingen.de/en/university/news-and-publications/","https://tunewsinternational.com/category/news-in-english/","https://www.komoot.com/guide/883/road-cycling-routes-around-tuebingen","https://www.thelocal.de/tag/tubingen","https://tuebingenresearchcampus.com/en/news/","https://www.my-stuwe.de/en/news/","https://www.germany.travel/en/cities-culture/tuebingen.html","https://tuebingenresearchcampus.com/en/tuebingen/living-in-tuebingen/going-to-the-doctor/","https://en.wikivoyage.org/wiki/T%C3%BCbingen"]'

##################################
# Crawling variables
##################################
# Text around the link to be crawled.
CRAWL_SURROUNDING_TEXT_LENGTH=10

# Every possible Tübingen writing styles
TUEBINGEN_WRITING_STYLES='["tubingen", "tuebingen", "tübingen", "tã¼bingen"]'

# Threshold value for classifying English content in a document.
CRAWL_ENGLISH_CLASSIFICATION_THRESHOLD=0.3

# Threshold value for classifying English content in a document when multiply languages are detected.
# In this case, prob must be 1 / n + this threshold.
CRAWL_ENGLISH_CLASSIFICATION_MULTI_THRESHOLD=0.1

# Timeout (in seconds) for each HTTP request during crawling.
CRAWL_TIMEOUT=5

# Time to render objects after the page is loaded (in seconds).
CRAWL_RENDER_TIMEOUT=8

# Number of retries for failed HTTP requests during crawling.
CRAWL_RETRIES=3

# List of HTTP status codes to retry the request if encountered during crawling.
CRAWL_RETRIES_IF_STATUS='[500, 502, 503, 504]'

# Backoff factor for exponential backoff during retries. Exponential seems to be good,
# especially for bad connection.
CRAWL_BACKOFF_FACTOR=1

# How many redirect do we accept before we stop following them.
CRAWL_REDIRECTION_LIMIT=5

# Raise error on status. Set to false to deactivate noisy error of requests and use our own nice.
CRAWL_RAISE_ON_STATUS=false

# List of domains to exclude from the crawling process.
CRAWL_BLACK_LIST='["airbnb","yahoo","swr","alamy","free-apply","nih","flickr","tiktok","pinterest","springer","instagram","gea","kreis-tuebingen","whatsapp","adscientificindex","tagblatt"]'

# Crawl priority list
CRAWL_PRIORITY_LIST='["en.wikipedia", "uni-tuebingen.de/en"]'

# List of file extensions to exclude from crawling.
CRAWL_EXCLUDED_EXTENSIONS='["js","css","jpg","jpeg","png","gif","pdf","ogg"]'

##################################
# Spacy environment variables
##################################
# Spacy model for initial tokenizing.
SPACY_MODEL=en_core_web_lg

# Ignore words having length larger than this
REMOVE_LONG_WORD_THRESHOLD=15

##################################
# Invertex index variables
##################################

# File path of the invertex index
INDEX_FILE=${OUTPUT_DIR}/index.pickle

##################################
#  Ranking variables
##################################

# Where to place the TFIDF vectorizer
TFIDF_VECTORIZER_FILE=${OUTPUT_DIR}/tfidf.pickle

# NGram parameter of the TFIDF vectorizer
TFIDF_NGRAM_RANGE='[1,2]'

# Where the directed link graph will be stored.
DIRECTED_LINK_GRAPH_FILE=${OUTPUT_DIR}/directed_link_graph.pickle

# PageRank file
PAGERANK_FILE=${OUTPUT_DIR}/pagerank.json

# PageRank initialization
PAGERANK_PERSONALIZATION='{ "tuebingen": 0.1, "wikipedia": 0.1 }'

# PageRank max_iter
PAGERANK_MAX_ITER=1000