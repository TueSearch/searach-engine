# Docker Compose file for TueSearch

version: '3.9'
services:
  ############################################################
  # MySQL models
  ############################################################
  mysql:
    build:
      context: .
      dockerfile: docker/database.Dockerfile
    container_name: mysql
    restart: unless-stopped
    ports:
      - '3306:3306'
    env_file:
      - .env
    volumes:
      - database_volume_3:/var/lib/mysql
    networks:
      - mysql_net
  ############################################################
  # phpmyadmin
  ############################################################
  phpmyadmin:
    image: phpmyadmin/phpmyadmin
    container_name: phpmyadmin
    env_file:
      - .env
    restart: always
    networks:
      - mysql_net
    ports:
      - '8080:80'
  ############################################################
  # Train the URL classifier.
  ############################################################
  train_url_classifier:
    build:
      context: .
      dockerfile: docker/backend.Dockerfile
    container_name: train_url_classifier
    restart: 'on-failure'
    command: 'python3 -m crawler.ml_models.url_relevance_trainer'
    env_file:
      - .env
    networks:
      - mysql_net
    volumes:
      - volume_3:/opt/tuesearch
  ############################################################
  # Initialize models.
  # Feed the models with initial jobs and initial documents.
  # Will run once.
  ############################################################
  initialize_database:
    build:
      context: .
      dockerfile: docker/backend.Dockerfile
    container_name: initialize_database
    restart: 'on-failure'
    command: 'python3 -m scripts.initialize_database'
    env_file:
      - .env
    networks:
      - mysql_net
    volumes:
      - volume_3:/opt/tuesearch
  ############################################################
  # Initialize models.
  # Feed the models with initial jobs and initial documents.
  # Will run once.
  ############################################################
  update_priority:
    build:
      context: .
      dockerfile: docker/backend.Dockerfile
    container_name: update_priority
    restart: 'on-failure'
    command: 'python3 -m crawler.update_priority'
    env_file:
      - .env
    networks:
      - mysql_net
    volumes:
      - volume_3:/opt/tuesearch
  ############################################################
  # Initialize models.
  # Feed the models with initial jobs and initial documents.
  # Will run once.
  ############################################################
  update_relevance:
    build:
      context: .
      dockerfile: docker/backend.Dockerfile
    container_name: update_relevance
    restart: 'on-failure'
    command: 'python3 -m crawler.update_relevance'
    env_file:
      - .env
    networks:
      - mysql_net
    volumes:
      - volume_3:/opt/tuesearch
  ############################################################
  # Start manager.
  ############################################################
  manager:
    build:
      context: .
      dockerfile: docker/backend.Dockerfile
    container_name: manager
    restart: 'always'
    command: '/home/tuesearch/.local/bin/gunicorn -w 3 -b 0.0.0.0:6000 crawler.manager.main:app'
    ports:
      - '6000:6000'
    env_file:
      - .env
    networks:
      - mysql_net
  ############################################################
  # Start the worker.
  ############################################################
  worker:
    build:
      context: .
      dockerfile: docker/backend.Dockerfile
    restart: 'on-failure'
    depends_on:
      - train_url_classifier
    command: 'python3 -m crawler.worker.main -n 4'
    env_file:
      - .env
    networks:
      - mysql_net
    volumes:
      - volume_3:/opt/tuesearch
  ############################################################
  # Start the worker in loop.
  #
  # So there's apparently problem with long running processes
  # which use spacy.
  # The current solution is to restart the processes sporadically.
  #
  # See: https://github.com/explosion/spaCy/issues/3618
  #
  # This task will run the worker on 50 websites and restart it.
  ############################################################
  loop_worker:
    build:
      context: .
      dockerfile: docker/backend.Dockerfile
    depends_on:
      - train_url_classifier
    restart: 'unless-stopped'
    command: 'python3 -m crawler.worker.main -n 50'
    env_file:
      - .env
    environment:
      - OMP_NUM_THREADS=1 # Make XGBoost work only with one thread.
    networks:
      - mysql_net
    volumes:
      - volume_3:/opt/tuesearch
  ############################################################
  # Build indexer.
  ############################################################
  update_index:
    build:
      context: .
      dockerfile: docker/backend.Dockerfile
    container_name: update_index
    restart: 'on-failure'
    command: 'python3 -m backend.update_index'
    env_file:
      - .env
    volumes:
      - volume_3:/opt/tuesearch
    networks:
      - mysql_net
  ############################################################
  # Update metrics.
  ############################################################
  update_metrics:
    build:
      context: .
      dockerfile: docker/backend.Dockerfile
    container_name: update_metrics
    restart: 'on-failure'
    command: 'python3 -m backend.update_metrics'
    env_file:
      - .env
    volumes:
      - volume_3:/opt/tuesearch
    networks:
      - mysql_net
  ############################################################
  # Start backend.
  # Persistent process.
  ############################################################
  backend_server:
    build:
      context: .
      dockerfile: docker/backend.Dockerfile
    container_name: backend_server
    ports:
      - '4000:4000'
    restart: 'always'
    command: 'python3 -m backend.app'
    env_file:
      - .env
    volumes:
      - volume_3:/opt/tuesearch
    networks:
      - mysql_net
  ############################################################
  # Start backend.
  # Persistent process.
  ############################################################
  backend_mockup_server:
    build:
      context: .
      dockerfile: docker/backend.Dockerfile
    container_name: backend_mockup_server
    ports:
      - '4001:4001'
    restart: 'always'
    command: 'python3 -m backend.app_mock'
  ############################################################
  # Start statistic server.
  # Persistent process.
  ############################################################
  backend_statistic_server:
    build:
      context: .
      dockerfile: docker/backend.Dockerfile
    container_name: backend_statistic_server
    ports:
      - '4002:4002'
    env_file:
      - .env
    restart: 'always'
    command: 'python3 -m backend.app_statistic'
    networks:
      - mysql_net
  ############################################################
  # Start frontend.
  # Persistent process.
  ############################################################
  frontend_server:
    build:
      context: .
      dockerfile: docker/frontend.Dockerfile
    container_name: frontend_server
    ports:
      - '5000:5000'
    restart: 'always'
    command: serve -s build -l 5000
    env_file:
      - frontend/.env
    networks:
      - mysql_net
  ############################################################
  # Test.
  # Run tests
  ############################################################
  run_unit_tests:
    build:
      context: .
      dockerfile: docker/backend.Dockerfile
    container_name: run_unit_tests
    restart: 'no'
    command: './scripts/run_tests.sh'
    env_file:
      - .env
    volumes:
      - .:/app
    networks:
      - mysql_net
volumes:
  database_volume_3:
    external: true
  volume_3:
    external: true
networks:
  mysql_net:
